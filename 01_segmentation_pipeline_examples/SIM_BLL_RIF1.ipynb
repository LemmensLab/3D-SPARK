{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import sys\n",
    "sys.path.insert(0, '') ## Insert in the quotes the path to where QuantSIM folder is in your computer.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import smbclient\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "import bisect\n",
    "from czifile import imread, CziFile\n",
    "import napari\n",
    "import scipy.ndimage as scipy_image\n",
    "import pyclesperanto_prototype as cle\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import gzip\n",
    "\n",
    "from QuantSIM.common import check_to_make_dir\n",
    "from QuantSIM.SIM_segment import SIM_segmentation, slide_channel_threshold\n",
    "from QuantSIM.SIM_analyze import SIM_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SIM_BLL_RIF1\n",
    "\n",
    "# Identification of nuclei by manually drawing masks before running pipeline.\n",
    "# 3 channels: EdU (clicked, AF647), Cy3-dUTP, SON speckles (immunostained, AF488).\n",
    "\n",
    "## Insert in the quotes the path to where you store 3D-SIM stack files (czi format) are in your computer.\n",
    "# The expected paths are:\n",
    "# 3D-SIM stack files: MAIN_PATH/RAWS_FOLDER/EXP_FOLDER/COND_FOLDER/ _Out.czi files\n",
    "# Mask files: MAIN_PATH/ROI_FOLDER/EXP_FOLDER/COND_FOLDER/ _dapi.czi files\n",
    "# output files: MAIN_PATH/RES_FOLDER/EXP_FOLDER_AUTO_ANALYSIS/slide/ many files organized in layers (viewable with Napari), tables, overlap_layers, overlap_tables\n",
    "\n",
    "MAIN_PATH = ''\n",
    "RAWS_FOLDER = 'raw_files'\n",
    "ROI_FOLDER = 'raw_masks'\n",
    "EXP_FOLDER = 'SIM_BLL_RIF1'\n",
    "RES_FOLDER = 'segmented/OTSU_THRESHOLDING'\n",
    "\n",
    "EXP_PATH = os.path.join(MAIN_PATH, RAWS_FOLDER, EXP_FOLDER)\n",
    "ROI_PATH = os.path.join(MAIN_PATH, ROI_FOLDER, EXP_FOLDER)\n",
    "RES_PATH = os.path.join(MAIN_PATH, RES_FOLDER, EXP_FOLDER + '_AUTO_ANALYSIS')\n",
    "#RES_MAIN_FOLDER = EXP_PATH[::-1].split('/', 1)[0][::-1] + '_AUTO_ANALYSIS' ## Double reverse search: Reverse to pick last element after splitting (which is first) and reverse again to get original substring.\n",
    "cle.select_device('M1')\n",
    "if not os.path.exists(EXP_PATH):\n",
    "    raise Exception('The experimental data path indicated could not be found.')\n",
    "\n",
    "if not os.path.exists(ROI_PATH):\n",
    "    raise Exception('Nuclei masks path indicated could not be found.')\n",
    "\n",
    "if not os.path.exists(RES_PATH):\n",
    "    check_to_make_dir(RES_PATH, known_path = MAIN_PATH)\n",
    "\n",
    "EXISTING_PATH = RES_PATH\n",
    "threshold_method = 'otsu'\n",
    "spot_sigma = 1\n",
    "outline_sigma = 0\n",
    "min_size = 50 # Considering a pixel as a cube, volume approx. 16000 nm**3. Nucleosome volume is 665 nm**3, 24 fully-packed nucleosomes/pixel volume (but chromatin status, signal intensity and light diffraction may alter nucleosome relative size).\n",
    "seg_keywords = ['raw','trim']\n",
    "min_size_overlap = 0\n",
    "pixel_to_nano_conversion = 25\n",
    "unit = 'nano'\n",
    "\n",
    "foldernames = ['raw','trim']\n",
    "\n",
    "for foldername,seg_keyword in zip(foldernames,seg_keywords):\n",
    "    RES_FOLDERNAME =  foldername+'__ss_{}__os_{}__min_size_{}__min_size_overlap_{}'.format(str(spot_sigma),str(outline_sigma), str(min_size), str(min_size_overlap))\n",
    "    RES_FOLDERNAME = os.path.join(RES_PATH, RES_FOLDERNAME)\n",
    "    for slide in os.listdir(EXP_PATH):\n",
    "        SLIDE_PATH = os.path.join(EXP_PATH, slide)\n",
    "        SLIDE_MASKS = os.path.join(ROI_PATH, slide)\n",
    "        if os.path.isdir(SLIDE_PATH) and os.path.isdir(SLIDE_MASKS):\n",
    "            czi_files = np.array(os.listdir(SLIDE_PATH))\n",
    "            czi_files = czi_files[['.czi' in czi_file for czi_file in czi_files]]\n",
    "            \n",
    "            # It is possible that there are multiple masks per image, or that there are multiple images with the same mask. The important thing is Image ID is the same to cross-check.\n",
    "            mask_files = np.array(os.listdir(SLIDE_MASKS))\n",
    "            mask_files = mask_files[['.tif' in mask_file for mask_file in mask_files]]\n",
    "            mask_id = [[],[]]\n",
    "            for mask_file in mask_files:\n",
    "                file_match = re.match(r'Image (\\d+).*\\.tif$', mask_file)\n",
    "                mask_id[0].append(file_match.group(0))\n",
    "                mask_id[1].append(file_match.group(1))\n",
    "            mask_id = np.array(mask_id)\n",
    "\n",
    "            # Link every image with every mask that share ID\n",
    "            linked_files_slide = []   ## Nested list. Lists inside have two elements: dapi filename and other channels filename\n",
    "            for czi_file in czi_files:\n",
    "                file_match = re.match(r'Image (\\d+).*\\.czi$', czi_file)\n",
    "                id_matches = np.where(mask_id[1] == file_match.group(1))[0].tolist() #Returns a tuple, each element would be dimensions of array. Since it is 1D-array, extract first element.\n",
    "                if len(id_matches) > 0:\n",
    "                    for id_match_pos in id_matches:\n",
    "                        linked_files_slide.append([czi_file,mask_id[0][id_match_pos]])\n",
    "            \n",
    "            # Now, for every pair identified, do analysis only if it is not the unprocessed image\n",
    "            for linked_files_image in linked_files_slide:\n",
    "                czi_file = linked_files_image[0]\n",
    "                mask_file = linked_files_image[1]\n",
    "                czi_match = re.match(r'Image \\d+(.*)\\.czi$', czi_file)\n",
    "                mask_match = re.match(r'Image \\d+(.*)\\.tif$', mask_file)\n",
    "                if czi_match != None:\n",
    "                    if czi_match.group(1) != '':\n",
    "                        RES_IMAGE_PATH = os.path.join(RES_FOLDERNAME, slide, czi_file[:-4] + '_' + mask_match.group(1)) # -4 because we remove .czi for naming the folder. Added mask_match to not overwrite images with multiple masks.\n",
    "                        if os.path.isdir(RES_IMAGE_PATH):\n",
    "                            continue\n",
    "                        check_to_make_dir(RES_IMAGE_PATH)\n",
    "                        EXISTING_PATH = RES_IMAGE_PATH\n",
    "                        MASK_PATH = os.path.join(SLIDE_MASKS, mask_file)\n",
    "                        IMAGE_PATH = os.path.join(SLIDE_PATH, czi_file)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "                channel_names = ['EdU','dUTP']\n",
    "                channel_colors = ['magenta','yellow']\n",
    "                dist_calculation_1 = dict(zip(channel_names,['centroid','centroid']))\n",
    "                dist_calculation_2 = dict(zip(channel_names,['maxima','maxima']))\n",
    "                channel_laser_wavelengths = []\n",
    "                metadata = CziFile(IMAGE_PATH)\n",
    "                xml_metadata = ET.ElementTree(ET.fromstring(metadata.metadata()))\n",
    "                root = xml_metadata.getroot()\n",
    "                for element in xml_metadata.iter('ExcitationWavelength'):\n",
    "                    channel_laser_wavelengths.append(element.text)\n",
    "                channel_laser_wavelengths = channel_laser_wavelengths[:int(round(len(channel_laser_wavelengths)/2,0))]\n",
    "                channel_laser_wavelengths = [int(round(float(i),0)) for i in channel_laser_wavelengths]\n",
    "                wavelengths_np = np.array(channel_laser_wavelengths)\n",
    "                channel_org = list(range(len(channel_laser_wavelengths)))\n",
    "                channel_org = ['skip_channel' for i in channel_org]\n",
    "                channel_org[np.where(wavelengths_np == 642)[0][0]] = 'EdU'\n",
    "                channel_org[np.where(wavelengths_np == 561)[0][0]] = 'dUTP'\n",
    "                Exp = SIM_segmentation(IMAGE_PATH, RES_IMAGE_PATH,\n",
    "                                    channel_names = channel_names,\n",
    "                                    channel_colors = channel_colors,\n",
    "                                    channel_org = channel_org,\n",
    "                                    MASK_PATH=MASK_PATH,\n",
    "                                    override = True)\n",
    "                Exp.anisotropy_correction()\n",
    "                Exp.image_truncation()\n",
    "                Exp.make_spatial_mask(prism_mode = True)\n",
    "                ## We are reusing the global threshold from whole image to do segmentation. The other option is redo the threshold in the cropped image, which may have slight changes (or a lot if the cell was dim in a channel).\n",
    "                Exp.segmentation_channel_intensity_based('EdU', spot_sigma = spot_sigma, outline_sigma = outline_sigma,\n",
    "                                                        inherit_threshold = Exp.channels_threshold_trunc['EdU'], use_roi_mask = True)\n",
    "                Exp.segmentation_channel_intensity_based('dUTP', spot_sigma = spot_sigma, outline_sigma = outline_sigma,\n",
    "                                                        inherit_threshold = Exp.channels_threshold_trunc['dUTP'], use_roi_mask = True)\n",
    "                Exp.select_segmentation(seg_keyword)\n",
    "                Exp.save_segmentation_layers(prefix='ALL_REGIONS__')\n",
    "                Exp.remove_small_regions('EdU',seg_keyword, min_size)\n",
    "                Exp.remove_small_regions('dUTP',seg_keyword, min_size)\n",
    "                ## Check if Exp has regions. If empty, skip to next image.\n",
    "                Exp.select_segmentation(seg_keyword)\n",
    "                if any(len(Exp.tables['004_segmented_regions'][channel].index) < 2 for channel in channel_names):\n",
    "                    continue\n",
    "                Exp.dist_to_core_and_rim()\n",
    "                Exp.save_segmentation_layers()\n",
    "                with open(os.path.join(RES_IMAGE_PATH,'000 SIM_segmentation extra info.txt'),'w') as txtfile:\n",
    "                    txtfile.write(str(dict(zip(channel_names,list(zip(channel_colors,channel_laser_wavelengths))))))\n",
    "                    txtfile.write('\\nScaling: {}'.format(str(Exp.voxelsizes)))\n",
    "                    txtfile.write('\\nInitial threshold method to find overall signal regions: {}'.format(threshold_method))\n",
    "                    txtfile.write('\\nThreshold calculated from max-z projection for truncation:')\n",
    "                    txtfile.write('\\n'+str(Exp.channels_threshold_trunc))\n",
    "                    txtfile.write('\\nCoordinates of truncation corner reference (YX):')\n",
    "                    txtfile.write('\\n'+str(Exp.trunc_refcoord))\n",
    "                    txtfile.write('\\nThreshold calculated from max-z projection for segmentation:')\n",
    "                    txtfile.write('\\n'+str(Exp.channels_threshold_seg))\n",
    "                    txtfile.write('\\nSpot sigma (local maxima identification)')\n",
    "                    txtfile.write('\\n'+str(spot_sigma))\n",
    "                    txtfile.write('\\nOutline sigma (Voronoi-watershed)')\n",
    "                    txtfile.write('\\n'+str(outline_sigma))\n",
    "                    txtfile.write('\\nMinimum segmented region size (pixels)')\n",
    "                    txtfile.write('\\n'+str(min_size))\n",
    "                    txtfile.write('\\nSegmentation selected')\n",
    "                    txtfile.write('\\n'+str(seg_keyword))\n",
    "                    txtfile.write('\\nMinimum overlap size (pixels)')\n",
    "                    txtfile.write('\\n'+str(min_size_overlap))\n",
    "                    txtfile.write('\\nunit conversion factor: ')\n",
    "                    txtfile.write('\\n'+str(pixel_to_nano_conversion))\n",
    "                    txtfile.write('\\nunit converted to: ')\n",
    "                    txtfile.write('\\n'+str(unit))\n",
    "                for channel in channel_names:\n",
    "                    Exp_channel = SIM_analysis(Exp, channel_1 = channel, channel_2 = channel)\n",
    "                    Exp_channel.neighbor_distance()\n",
    "                    Exp_channel.neighbor_distance(channels_ref = ['maxima','maxima'])\n",
    "                    Exp_channel.overlap_detection()\n",
    "                    Exp_channel.overlap_declumping()\n",
    "                    Exp_channel.two_channel_overlap_regions(overlap_stoich=(1,1))\n",
    "                    Exp_channel.measure_overlapping_regions(pixel_unit_conversion = 1, unit = 'pixel')\n",
    "                    Exp_channel.measure_overlapping_regions(pixel_unit_conversion = pixel_to_nano_conversion, unit = unit)\n",
    "                    Exp_channel.single_channel_cleanup()\n",
    "                    Exp_channel.save_segmentation_layers(prefix = 'one_channel__')\n",
    "                    del Exp_channel\n",
    "                for combo in itertools.combinations(channel_names, 2):\n",
    "                    Exp_overlap = SIM_analysis(Exp, channel_1 = combo[0], channel_2 = combo[1])\n",
    "                    Exp_overlap.neighbor_distance(channels_ref = [dist_calculation_1[combo[0]],dist_calculation_1[combo[1]]])\n",
    "                    Exp_overlap.neighbor_distance(channels_ref = [dist_calculation_2[combo[0]],dist_calculation_2[combo[1]]])\n",
    "                    Exp_overlap.overlap_detection(min_size_overlap = min_size_overlap)\n",
    "                    if all(['EdU' in combo,'dUTP' in combo]):\n",
    "                        Exp_overlap.overlap_declumping()\n",
    "                    Exp_overlap.save_segmentation_layers(prefix = 'two_channel_common__')\n",
    "                    ## PROBLEM: keep calculating things when they have no data, no overlaps to work with, should be empty but then gets confused...\n",
    "                    ## SOLUTION: ignore instances where there are less than 2 intersecting regions identified.\n",
    "                    if len(Exp_overlap.tables['102_intersection_regions'].index) < 2:\n",
    "                        with open(os.path.join(RES_IMAGE_PATH,'000 SIM_analysis {}_vs_{} extra info.txt'.format(str(combo[0]),str(combo[1]))), 'w') as txtfile:\n",
    "                            txtfile.write('Channels evaluated for overlap: {}'.format(str(combo)))\n",
    "                            for i in range(len(combo)):\n",
    "                                txtfile.write('\\n'+str(combo[i]))\n",
    "                                txtfile.write('\\n\\tValue\\tCount')\n",
    "                                txtfile.write('\\n'+str(Exp_overlap.tables['102_overlap_bool'].sum(axis = 1-i).value_counts().sort_index()))\n",
    "                                txtfile.write('\\nTotal: '+ str(Exp.tables['004_segmented_maxima'][combo[i]].shape[0]))\n",
    "                            txtfile.write('\\nFork structure number')\n",
    "                            txtfile.write('\\nInitiation: NA')\n",
    "                            txtfile.write('\\nOngoing: NA')\n",
    "                            txtfile.write('\\nTermination: NA')\n",
    "                        del Exp_overlap\n",
    "                        continue\n",
    "                    Exp_overlap.two_channel_overlap_regions(overlap_stoich=(0,0))\n",
    "                    Exp_overlap.measure_overlapping_regions(pixel_unit_conversion = 1, unit = 'pixel')\n",
    "                    #Exp_overlap.measure_overlapping_regions(pixel_unit_conversion = pixel_to_nano_conversion, unit = unit)\n",
    "                    Exp_overlap.save_segmentation_layers(prefix = 'two_channel_no_overlap__', common_results = False)\n",
    "                    del Exp_overlap.layers['105_stoich_0-to-0_segmented_labeled']\n",
    "                    Exp_overlap.two_channel_overlap_regions(overlap_stoich=(1,1))\n",
    "                    Exp_overlap.measure_overlapping_regions(pixel_unit_conversion = 1, unit = 'pixel')\n",
    "                    #Exp_overlap.measure_overlapping_regions(pixel_unit_conversion = pixel_to_nano_conversion, unit = unit)\n",
    "                    Exp_overlap.save_segmentation_layers(prefix = 'two_channel_ongoing__', common_results = False)\n",
    "                    ong_n = Exp_overlap.tables['105_overlap_labels'].shape[0]\n",
    "                    del Exp_overlap.layers['105_stoich_1-to-1_segmented_labeled']\n",
    "                    del Exp_overlap.tables['106_channel_measurements']\n",
    "                    del Exp_overlap.tables['106_overlap_measurements']\n",
    "                    Exp_overlap.two_channel_overlap_regions(overlap_stoich=(2,1))\n",
    "                    Exp_overlap.save_segmentation_layers(prefix = 'two_channel_initiation__', common_results = False)\n",
    "                    init_n = Exp_overlap.tables['105_overlap_labels'].shape[0]\n",
    "                    del Exp_overlap.layers['105_stoich_2-to-1_segmented_labeled']\n",
    "                    Exp_overlap.two_channel_overlap_regions(overlap_stoich=(1,2))\n",
    "                    Exp_overlap.save_segmentation_layers(prefix = 'two_channel_termination__', common_results = False)\n",
    "                    term_n = Exp_overlap.tables['105_overlap_labels'].shape[0]\n",
    "                    with open(os.path.join(RES_IMAGE_PATH,'000 SIM_analysis {}_vs_{} extra info.txt'.format(str(combo[0]),str(combo[1]))), 'w') as txtfile:\n",
    "                        txtfile.write('Channels evaluated for overlap: {}'.format(str(combo)))\n",
    "                        for i in range(len(combo)):\n",
    "                            txtfile.write('\\n'+str(combo[i]))\n",
    "                            txtfile.write('\\n\\tValue\\tCount')\n",
    "                            txtfile.write('\\n'+str(Exp_overlap.tables['102_overlap_bool'].sum(axis = 1-i).value_counts().sort_index()))\n",
    "                            txtfile.write('\\nTotal: '+ str(Exp.tables['004_segmented_maxima'][combo[i]].shape[0]))\n",
    "                        txtfile.write('\\nFork structure number')\n",
    "                        txtfile.write('\\nInitiation: '+ str(init_n))\n",
    "                        txtfile.write('\\nOngoing: '+ str(ong_n))\n",
    "                        txtfile.write('\\nTermination: '+ str(term_n))\n",
    "                    del Exp_overlap\n",
    "                del Exp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantSIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
